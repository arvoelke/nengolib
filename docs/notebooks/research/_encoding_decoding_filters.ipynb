{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  },
  "name": "",
  "signature": "sha256:f355523101b34b381f09756869f8a18ec60f99451728424a0f26b862fce077ae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Encoding and Decoding Filters\n",
      "\n",
      "This notebook contains some preliminary investigation into the use of encoding and decoding filters to approximate some given dynamics, _without_ the use of the RC training method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab\n",
      "try:\n",
      "    import seaborn as sns  # optional; prettier graphs\n",
      "except ImportError:\n",
      "    pass\n",
      "\n",
      "import numpy as np\n",
      "import nengo\n",
      "import nengolib\n",
      "from nengolib.synapses import HeteroSynapse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up the filters for each neuron (4 choices for each of encoding/decoding), and the target filter (a derivative)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_neurons = 2000\n",
      "rng = np.random.RandomState(0)\n",
      "\n",
      "encoding_filters = [nengolib.Lowpass(tau) for tau in rng.choice([1e-6, 0.001, 0.005, 0.01], size=n_neurons)] # uniform(0.00001, 0.02, size=n_neurons)]\n",
      "decoding_filters = [nengolib.Lowpass(tau) for tau in rng.choice([1e-6, 0.001, 0.005, 0.01], size=n_neurons)] # rng.uniform(0.00001, 0.02, size=n_neurons)]\n",
      "\n",
      "f_filter = nengolib.synapses.Highpass(0.01)\n",
      "\n",
      "train_dt = 0.0005\n",
      "train_length = 200\n",
      "train_solver = nengo.solvers.LstsqL2(reg=0.001)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Determine the weights independently of the decoders that construct the desired filter from the chosen encoding and decoding filters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = np.empty((train_length, n_neurons))\n",
      "for j, (eh, dh) in enumerate(zip(encoding_filters, decoding_filters)):\n",
      "    A[:, j] = nengolib.signal.LinearSystem(eh * dh).impulse(train_length, dt=train_dt)\n",
      "    \n",
      "Y = f_filter.impulse(train_length, dt=train_dt)\n",
      "\n",
      "df, _ = train_solver(A, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Observe the distribution of weights (4x4 = 16 possibilities), that are correlated with the taus of each filter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.figure()\n",
      "pylab.hist(df, bins=100)\n",
      "pylab.show()\n",
      "\n",
      "pylab.figure()\n",
      "pylab.scatter([eh.poles[0] for eh in encoding_filters], df)\n",
      "pylab.scatter([dh.poles[0] for dh in decoding_filters], df)\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that this reconstructs the desired impulse response."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = np.arange(train_length) * train_dt\n",
      "output = np.dot(A, df)\n",
      "\n",
      "pylab.figure()\n",
      "pylab.plot(t, Y, linestyle='--', label=\"Target\")\n",
      "pylab.plot(t, output, label=\"Output\")\n",
      "pylab.xlabel(\"Time (s)\")\n",
      "pylab.ylabel(\"Impulse Response\")\n",
      "pylab.legend()\n",
      "pylab.show()\n",
      "\n",
      "freqs = np.fft.rfftfreq(len(Y), d=train_dt)\n",
      "\n",
      "pylab.figure()\n",
      "pylab.plot(freqs, abs(np.fft.rfft(Y)), linestyle='--', label=\"Target\")\n",
      "pylab.plot(freqs, abs(np.fft.rfft(output)), label=\"Output\")\n",
      "pylab.xlabel(\"Frequency (Hz)\")\n",
      "pylab.ylabel(\"Power\")\n",
      "pylab.legend()\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check that this correctly filters white noise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = 0.0005\n",
      "u = nengo.processes.WhiteSignal(1.0, high=5).run(1.0, dt=dt)\n",
      "\n",
      "y = f_filter.filt(u, dt=dt, y0=0)\n",
      "\n",
      "y_act = np.zeros_like(y)\n",
      "for j, (eh, dh) in enumerate(zip(encoding_filters, decoding_filters)):\n",
      "    y_act += df[j] * (eh * dh).filt(u, dt=dt, y0=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.figure()\n",
      "pylab.plot(y, linestyle='--', label=\"Target\")\n",
      "pylab.plot(y_act, label=\"Output\")\n",
      "pylab.xlabel(\"Time (s)\")\n",
      "pylab.legend()\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now use these weights to scale the decoders (independently solved for) in a feed-forward network. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = 0.0005\n",
      "neuron_type = nengo.LIFRate()\n",
      "ens_seed = 42\n",
      "process_seed = 43\n",
      "encoders_rng = np.random.RandomState(seed=44)\n",
      "\n",
      "with nengolib.Network() as model:\n",
      "    stim = nengo.Node(output=nengo.processes.WhiteSignal(1.0, high=10, y0=0, seed=process_seed))\n",
      "    output = nengo.Node(size_in=1)\n",
      "\n",
      "    encoders = nengolib.stats.sphere.sample(n_neurons, 1, rng=encoders_rng)    \n",
      "    ens = nengo.Ensemble(n_neurons, 1, neuron_type=neuron_type, encoders=encoders, seed=ens_seed)\n",
      "\n",
      "    encoding_synapses = nengo.Node(\n",
      "        size_in=1, output=HeteroSynapse(encoding_filters, dt=dt))\n",
      "\n",
      "    decoding_synapses = nengo.Node(\n",
      "        size_in=n_neurons, output=HeteroSynapse(decoding_filters, dt=dt, elementwise=True))\n",
      "\n",
      "    nengo.Connection(stim, encoding_synapses, synapse=None)\n",
      "\n",
      "    conn = nengo.Connection(ens, nengo.Node(size_in=1), synapse=None)\n",
      "    decoders = df[None, :] * n_neurons * nengo.Simulator(model).data[conn].weights\n",
      "\n",
      "    nengo.Connection(encoding_synapses, ens.neurons, function=lambda x: encoders[:, 0]*x, synapse=None)\n",
      "    nengo.Connection(ens.neurons, decoding_synapses, synapse=None)\n",
      "    nengo.Connection(decoding_synapses, output, transform=decoders, synapse=None)\n",
      "\n",
      "    p_stim = nengo.Probe(stim, synapse=None)\n",
      "    p_output = nengo.Probe(output, synapse=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengo.Simulator(model, dt=dt) as sim:\n",
      "    sim.run(0.5)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "expected = f_filter.filt(sim.data[p_stim], dt=dt, y0=0)\n",
      "\n",
      "pylab.figure(figsize=(16, 6))\n",
      "pylab.title(\"Highpass Filter Analytically Approximated using Encoding/Decoding Filters\")\n",
      "pylab.plot(sim.trange(), expected, lw=2, linestyle='--', label=\"Target\")\n",
      "pylab.plot(sim.trange(), sim.data[p_output], lw=2, label=\"Output\")\n",
      "pylab.xlabel(\"Time (s)\")\n",
      "pylab.legend()\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The systematic bias comes from the fact that each subgroup of decoders that are modulated by the same weight do not by themselves approximate the desired function, as shown below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with nengolib.Network() as model:\n",
      "    stim = nengo.Node(output=nengo.processes.WhiteSignal(1.0, high=10, y0=0, seed=1))\n",
      "    output = nengo.Node(size_in=1)\n",
      "    output1 = nengo.Node(size_in=1)\n",
      "    output2 = nengo.Node(size_in=1)\n",
      "\n",
      "    x = nengo.Ensemble(n_neurons, 1, seed=0)\n",
      "    nengo.Connection(stim, x, synapse=None)\n",
      "    \n",
      "    conn = nengo.Connection(x, output, synapse=None)\n",
      "    decoders = np.squeeze(nengo.Simulator(model).data[conn].weights)\n",
      "    \n",
      "    d1 = np.zeros_like(decoders)\n",
      "    d2 = np.zeros_like(decoders)\n",
      "    d1[:n_neurons // 2] = 2*decoders[:n_neurons // 2]\n",
      "    d2[n_neurons // 2:] = 2*decoders[n_neurons // 2:]\n",
      "    \n",
      "    nengo.Connection(x.neurons, output1, transform=d1[None, :], synapse=None)\n",
      "    nengo.Connection(x.neurons, output2, transform=d2[None, :], synapse=None)\n",
      "    \n",
      "    p_output = nengo.Probe(output)\n",
      "    p_output1 = nengo.Probe(output1)\n",
      "    p_output2 = nengo.Probe(output2)\n",
      "    \n",
      "with nengo.Simulator(model) as sim:\n",
      "    sim.run(0.005)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.figure()\n",
      "pylab.plot(sim.trange(), sim.data[p_output], linestyle='--', lw=3, alpha=0.8, label=\"Output\")\n",
      "pylab.plot(sim.trange(), sim.data[p_output1], lw=3, alpha=0.8, label=\"1\")\n",
      "pylab.plot(sim.trange(), sim.data[p_output2], lw=3, alpha=0.8, label=\"2\")\n",
      "pylab.plot(sim.trange(), (sim.data[p_output1] + sim.data[p_output2]) / 2, lw=3, alpha=0.8, label=\"1+2\")\n",
      "pylab.xlabel(\"Time (s)\")\n",
      "pylab.legend()\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "collapsed": true
     },
     "source": [
      "Improvements are possible by taking into account which neurons have similar filters to locally optimize the function near each subgroup, or take into account this effect using knowledge of the filter weights."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}