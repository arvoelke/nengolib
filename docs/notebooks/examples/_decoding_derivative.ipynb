{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  },
  "name": "",
  "signature": "sha256:f2bd0613a53622948adf0c4a66197c59f8a5d9b591a713992fd7c015eb244469"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Differentiation using Heterogeneous Synapses\n",
      "\n",
      "The following model shows how to solve for the decoders over time to compute functions that depend on past inputs (i.e. a filter). To do this accurately in some cases, without principle 3, it becomes necessary to introduce heterogeneous synapses, so that each neuron's \"augmented encoder\" will extract different \"temporal features\" from the input.\n",
      "\n",
      "Note, this won't be as good as just using `LinearNetwork` to build the desired filter, because that can use a passthrough. A passthrough is what's needed to compute the highpass transfer function exactly; if a passthrough is \"allowed\", this problem is more trivial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import pylab\n",
      "try:\n",
      "    import seaborn as sns  # optional; prettier graphs\n",
      "except ImportError:\n",
      "    pass\n",
      "\n",
      "import numpy as np\n",
      "from scipy.linalg import svd\n",
      "\n",
      "import nengo\n",
      "import nengolib\n",
      "from nengolib.synapses import HeteroSynapse\n",
      "\n",
      "\n",
      "def make_model(synapses, encoders, decoders, n_neurons, tau_derivative,\n",
      "               seed, stim_seed, dt, T, stim_cutoff_freq=15, stim_rms=0.5,\n",
      "               neuron_type=nengo.LIF()):\n",
      "\n",
      "    with nengolib.Network(seed=seed) as model:\n",
      "\n",
      "        # White noise input\n",
      "        stim = nengo.Node(output=nengo.processes.WhiteSignal(\n",
      "            T, high=stim_cutoff_freq, rms=stim_rms, seed=stim_seed))\n",
      "\n",
      "        # Heterogeneous synapses (one per neuron)\n",
      "        x_synapses = nengo.Node(\n",
      "            size_in=1, output=HeteroSynapse(synapses, dt=dt))\n",
      "\n",
      "        # Ensemble that encodes the signal\n",
      "        x = nengo.Ensemble(\n",
      "            n_neurons, 1, encoders=encoders, neuron_type=neuron_type)\n",
      "        \n",
      "        # Optional decoding (linear readout)\n",
      "        if decoders is None:\n",
      "            decoders = np.zeros((n_neurons, 1))\n",
      "        y = nengo.Node(size_in=1)\n",
      "\n",
      "        # Connections\n",
      "        nengo.Connection(stim, x_synapses, synapse=None)\n",
      "        nengo.Connection(x_synapses, x.neurons,\n",
      "                         function=lambda x: x*encoders[:, 0], synapse=None)\n",
      "        nengo.Connection(x.neurons, y, transform=decoders.T,\n",
      "                         synapse=tau_derivative)\n",
      "\n",
      "        # Probes\n",
      "        p_input = nengo.Probe(stim, synapse=None)\n",
      "        #p_synapses = nengo.Probe(x_synapses, synapse=tau_derivative)\n",
      "        p_x = nengo.Probe(x.neurons, synapse=tau_derivative)\n",
      "        p_y = nengo.Probe(y, synapse=None)\n",
      "\n",
      "        return model, (p_input, p_x, p_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_neurons = 1000\n",
      "tau_derivative = 0.005\n",
      "\n",
      "seed = 0\n",
      "rng = np.random.RandomState(seed)\n",
      "\n",
      "taus = rng.uniform(0.0005, 0.01, size=n_neurons)  # encoding filters\n",
      "synapses = [nengolib.Lowpass(tau) for tau in taus]\n",
      "encoders = nengolib.stats.sphere.sample(n_neurons, rng=rng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will approximate the filter $H(s) = 2\\tau s / (\\tau s + 1)$. This is the derivative $s$ multiplied by a lowpass $1 / (\\tau s + 1)$ (to make it causal) and scaled by $2\\tau$ (for normalization)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "H = 2 * nengolib.synapses.Highpass(tau_derivative)\n",
      "\n",
      "h_size = 1000\n",
      "h_dt = 0.001\n",
      "freqs = np.fft.rfftfreq(h_size, d=h_dt)\n",
      "desired = H.impulse(h_size, dt=h_dt)\n",
      "\n",
      "pylab.figure()\n",
      "pylab.title(\"Derivative Filter (Fourier Domain)\")\n",
      "pylab.plot(freqs, abs(np.fft.rfft(desired)), label=\"Desired\")\n",
      "pylab.xlabel(\"Frequency ($Hz$)\")\n",
      "#pylab.legend(loc='center right')\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training\n",
      "\n",
      "To solve for the decoders, we first simulate the network on a $15\\,Hz$ training signal and collect the spike data filtered by $\\tau$. Then use a decoder solver (e.g. LstsqL2) where the target points are $y = (x \\ast h)(t)$ given the filtered spikes $x$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dt = 0.0002\n",
      "T = 1.0\n",
      "\n",
      "model, (p_input, p_x, p_y) = make_model(\n",
      "    synapses, encoders, decoders=None, n_neurons=n_neurons,\n",
      "    tau_derivative=tau_derivative, seed=seed, stim_seed=0, dt=dt, T=T)\n",
      "sim = nengo.Simulator(model, dt=dt)\n",
      "sim.run(T, progress_bar=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# AD = Y\n",
      "X = sim.data[p_input]\n",
      "A = sim.data[p_x]\n",
      "Y = H.filt(X, dt=dt)\n",
      "decoders, info = nengo.solvers.LstsqL2()(A, Y)\n",
      "Y_hat = np.dot(A, decoders)\n",
      "\n",
      "\n",
      "gamma = np.dot(A.T, A)\n",
      "U, S, V = svd(gamma)\n",
      "chi = np.dot(A, U)\n",
      "pylab.figure(figsize=(12, 7))\n",
      "pylab.title(\"SVD of Gamma Matrix\")\n",
      "pylab.plot(sim.trange(), X, label=\"Input\")\n",
      "for i in range(3):\n",
      "    pylab.plot(sim.trange(), chi[:, i] / len(chi), label=r\"$\\chi_%d$\" % i)\n",
      "pylab.legend(loc='best')\n",
      "pylab.show()\n",
      "\n",
      "\n",
      "def plot_signals(X, Y, Y_hat, offset=100):\n",
      "    pylab.figure(figsize=(12, 7))\n",
      "    pylab.title(\"Derivative of Signal (RMSE: %.3f)\" % nengo.utils.numpy.rmse(Y, Y_hat))    \n",
      "    pylab.plot(sim.trange()[offset:], X[offset:], label=\"Input\")\n",
      "    pylab.plot(sim.trange()[offset:], Y[offset:], label=\"Ideal\")\n",
      "    pylab.plot(sim.trange()[offset:], Y_hat[offset:], label=\"Approximation\")\n",
      "    pylab.legend(loc='best')\n",
      "    pylab.xlabel(\"Time ($s$)\")\n",
      "    #pylab.ylim(-1, 1)\n",
      "    pylab.show()\n",
      "    \n",
      "plot_signals(X, Y, Y_hat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Validation\n",
      "\n",
      "Now we demonstrate that these same decoders generalize to other signals, even at a different frequency (e.g. $10\\,Hz$)!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model, (p_input, p_x, p_y) = make_model(\n",
      "    synapses, encoders, decoders=decoders, n_neurons=n_neurons,\n",
      "    tau_derivative=tau_derivative, seed=seed, stim_seed=1, dt=dt, T=T,\n",
      "    stim_cutoff_freq=10)\n",
      "sim = nengo.Simulator(model, dt=dt)\n",
      "sim.run(T, progress_bar=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = sim.data[p_input]\n",
      "Y = H.filt(X, dt=dt)\n",
      "Y_hat = sim.data[p_y]\n",
      "\n",
      "plot_signals(X, Y, Y_hat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lastly it is natural to wonder how crucial it is to have heterogeneous synapses. We can answer that question by repeating this with a number of different sampling widths, i.e. $\\tau \\sim \\mathcal{U}[L, L + width]$ for various $width$ parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_samples = 5\n",
      "plot_x = []\n",
      "plot_y = []\n",
      "T = 1\n",
      "\n",
      "for width in np.linspace(0, 0.03, num_samples):\n",
      "    L, U = 0.0005, 0.0005 + width\n",
      "\n",
      "    rng = np.random.RandomState(seed)\n",
      "    taus = rng.uniform(L, U, size=n_neurons)\n",
      "    synapses = [nengolib.Lowpass(tau) for tau in taus]\n",
      "\n",
      "    model, (p_input, p_x, p_y) = make_model(\n",
      "        synapses, encoders, decoders=None, n_neurons=n_neurons,\n",
      "        tau_derivative=tau_derivative, seed=seed, stim_seed=0, dt=dt, T=T)\n",
      "    sim = nengo.Simulator(model, dt=dt)\n",
      "    sim.run(T, progress_bar=False)\n",
      "\n",
      "    X = sim.data[p_input]\n",
      "    A = sim.data[p_x]\n",
      "    Y = H.filt(X, dt=dt)\n",
      "    decoders, info = nengo.solvers.LstsqL2()(A, Y)\n",
      "    Y_hat = np.dot(A, decoders)\n",
      "\n",
      "    plot_x.append(width)\n",
      "    plot_y.append(nengo.utils.numpy.rmse(Y, Y_hat))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import curve_fit\n",
      "\n",
      "def fit(x, a, b, c, d, e):\n",
      "    return a*np.exp(-b*x) + c*np.exp(-d*x) + e\n",
      "\n",
      "popt, pcov = curve_fit(fit, plot_x, plot_y, bounds=(0, [1., 10000., 1., 10000., 1.]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.figure()\n",
      "pylab.title(\"Effect of Increasing Heterogeneity\")\n",
      "pylab.plot(plot_x, plot_y)\n",
      "#pylab.plot(plot_x, fit(np.asarray(plot_x), *popt), color='green', linewidth=1, alpha=0.8)\n",
      "pylab.xlabel(r\"$\\tau$ width ($ms$)\")\n",
      "pylab.ylabel(\"RMSE\")\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}
